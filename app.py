import streamlit as st
import pandas as pd
import numpy as np
import requests
import os
import holidays
import itertools
from datetime import datetime, timedelta
from fpdf import FPDF
import subprocess
import geopandas as gpd
import json
import requests
import io
import json
from shapely.geometry import Point
from scipy.spatial import cKDTree

st.set_page_config(page_title="Veri GÃ¼ncelleme", layout="wide")
st.title("ğŸ“¦ GÃ¼nlÃ¼k SuÃ§ Verisi Ä°ÅŸleme ve Ã–zetleme Paneli")

DOWNLOAD_URL = "https://github.com/cem5113/crime_prediction_data/releases/download/latest/sf_crime.csv"
DOWNLOAD_911_URL = "https://github.com/cem5113/crime_prediction_data/releases/download/v1.0.1/sf_911_last_5_year.csv"
DOWNLOAD_311_URL = "https://github.com/cem5113/crime_prediction_data/releases/download/v1.0.2/sf_311_last_5_years.csv"
POPULATION_PATH = "sf_population.csv"
DOWNLOAD_BUS_URL = "https://github.com/cem5113/crime_prediction_data/raw/main/sf_bus_stops_with_geoid.csv"
DOWNLOAD_TRAIN_URL = "https://github.com/cem5113/crime_prediction_data/raw/main/sf_train_stops_with_geoid.csv"
DOWNLOAD_POIS_URL = "https://github.com/cem5113/crime_prediction_data/raw/main/sf_pois.geojson"
RISKY_POIS_JSON_PATH = "risky_pois_dynamic.json"
DOWNLOAD_POLICE_URL = "https://github.com/cem5113/crime_prediction_data/raw/main/sf_police_stations.csv"
DOWNLOAD_GOV_URL = "https://github.com/cem5113/crime_prediction_data/raw/main/sf_government_buildings.csv"
DOWNLOAD_WEATHER_URL = "https://github.com/cem5113/crime_prediction_data/releases/download/latest/sf_weather_5years.csv"

def update_bus_data_if_needed():
    import geopandas as gpd
    from shapely.geometry import Point
    import os

    api_url = "https://data.sfgov.org/resource/i28k-bkz6.json"
    timestamp_file = "bus_stops_last_update.txt"

    def is_month_passed(file):
        if os.path.exists(file):
            with open(file, "r") as f:
                last = f.read().strip()
            try:
                last_date = datetime.strptime(last, "%Y-%m-%d")
                return (datetime.today() - last_date).days >= 30
            except:
                return True
        return True

    if is_month_passed(timestamp_file):
        try:
            response = requests.get(api_url)
            if response.status_code == 200:
                bus_data = response.json()
                df = pd.DataFrame(bus_data)

                # latitude / longitude sÃ¼tunlarÄ±nÄ± float olarak al
                df = df.dropna(subset=["latitude", "longitude"])
                df["stop_lat"] = df["latitude"].astype(float)
                df["stop_lon"] = df["longitude"].astype(float)

                # GeoDataFrame'e Ã§evir
                gdf_stops = gpd.GeoDataFrame(
                    df,
                    geometry=gpd.points_from_xy(df["stop_lon"], df["stop_lat"]),
                    crs="EPSG:4326"
                )

                # Census bloklarÄ±nÄ± oku
                census_path = "sf_census_blocks_with_population.geojson"
                gdf_blocks = gpd.read_file(census_path)[["GEOID", "geometry"]].to_crs("EPSG:4326")

                # Spatial join
                gdf_joined = gpd.sjoin(gdf_stops, gdf_blocks, how="left", predicate="within")
                gdf_joined["GEOID"] = gdf_joined["GEOID"].astype(str).str.zfill(11)
                gdf_joined.drop(columns=["geometry", "index_right"], errors="ignore").to_csv("sf_bus_stops_with_geoid.csv", index=False)

                # Tarih kaydet
                with open(timestamp_file, "w") as f:
                    f.write(datetime.today().strftime("%Y-%m-%d"))

                st.success("ğŸšŒ OtobÃ¼s duraklarÄ± Socrata API'den indirildi ve GEOID ile eÅŸleÅŸtirildi.")

                # âœ… Ã–nizleme gÃ¶ster
                st.write("ğŸ“Œ [sf_bus_stops_with_geoid.csv] sÃ¼tunlar:")
                st.write(gdf_joined.columns.tolist())
                st.write("ğŸ“‹ Ä°lk 3 satÄ±r:")
                st.dataframe(gdf_joined.head(3))

            else:
                st.warning(f"âš ï¸ OtobÃ¼s verisi indirilemedi: {response.status_code}")
        except Exception as e:
            st.error(f"âŒ OtobÃ¼s verisi gÃ¼ncellenemedi: {e}")
    else:
        st.info("ğŸ“… OtobÃ¼s verisi bu ay zaten gÃ¼ncellendi.")

def update_train_data_if_needed():
    import zipfile
    import geopandas as gpd
    import pandas as pd
    import os
    from datetime import datetime

    zip_path = "bart_gtfs.zip"
    timestamp_file = "train_stops_last_update.txt"

    def is_month_passed(file):
        if os.path.exists(file):
            with open(file, "r") as f:
                last = f.read().strip()
            try:
                last_date = datetime.strptime(last, "%Y-%m-%d")
                return (datetime.today() - last_date).days >= 30
            except:
                return True
        return True

    if is_month_passed(timestamp_file):
        try:
            response = requests.get(DOWNLOAD_TRAIN_URL)
            if response.status_code == 200:
                with open(zip_path, "wb") as f:
                    f.write(response.content)
                with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                    zip_ref.extract("stops.txt", ".")
                os.rename("stops.txt", "sf_train_stops.csv")
                with open(timestamp_file, "w") as f:
                    f.write(datetime.today().strftime("%Y-%m-%d"))
                st.success("ğŸš† BART tren duraklarÄ± gÃ¼ncellendi (sf_train_stops.csv)")

                # === GEOID EÅLEME ===
                train_df = pd.read_csv("sf_train_stops.csv")
                st.write("ğŸ“‹ [Tren DuraklarÄ±] SÃ¼tunlar:")
                st.write(train_df.columns.tolist())
                st.write("ğŸš‰ [Tren DuraklarÄ±] Ä°lk 3 SatÄ±r:")
                st.dataframe(train_df.head(3))

                gdf_stops = gpd.GeoDataFrame(
                    train_df.dropna(subset=["stop_lat", "stop_lon"]),
                    geometry=gpd.points_from_xy(train_df["stop_lon"], train_df["stop_lat"]),
                    crs="EPSG:4326"
                )

                census_path = "https://github.com/cem5113/crime_prediction_data/raw/main/sf_pois.geojson"
                gdf_blocks = gpd.read_file(census_path)[["GEOID", "geometry"]].to_crs("EPSG:4326")

                gdf_joined = gpd.sjoin(gdf_stops, gdf_blocks, how="left", predicate="within")
                gdf_joined["GEOID"] = gdf_joined["GEOID"].astype(str).str.zfill(11)

                final_df = gdf_joined.drop(columns=["geometry", "index_right"], errors="ignore")
                final_df.to_csv("sf_train_stops_with_geoid.csv", index=False)

                st.success("ğŸ“Œ GEOID ile eÅŸleÅŸtirilmiÅŸ tren duraklarÄ± oluÅŸturuldu (sf_train_stops_with_geoid.csv)")
                st.write("ğŸ“‹ [Tren + GEOID] SÃ¼tunlar:")
                st.write(final_df.columns.tolist())
                st.write("ğŸš‰ [Tren + GEOID] Ä°lk 3 SatÄ±r:")
                st.dataframe(final_df.head(3))

            else:
                st.warning(f"âš ï¸ Tren verisi indirilemedi: {response.status_code}")
        except Exception as e:
            st.error(f"âŒ Tren verisi indirme hatasÄ±: {e}")
    else:
        st.info("ğŸ“… Tren verisi bu ay zaten gÃ¼ncellenmiÅŸ.")

def update_pois_if_needed():
    import os
    import pandas as pd
    import streamlit as st
    from datetime import datetime
    import update_pois  # ğŸ” SUBPROCESS YERÄ°NE DÄ°REKT MODÃœL GÄ°BÄ° KULLAN

    timestamp_file = "poi_last_update.txt"

    def is_month_passed(file):
        if os.path.exists(file):
            with open(file, "r") as f:
                last = f.read().strip()
            try:
                last_date = datetime.strptime(last, "%Y-%m-%d")
                return (datetime.today() - last_date).days >= 30
            except:
                return True
        return True

    if is_month_passed(timestamp_file):
        try:
            st.info("ğŸ“¥ POI verisi gÃ¼ncelleniyor...")

            # ğŸ“¦ POI iÅŸleme (temizleme ve risk hesaplama)
            update_pois.process_pois()
            update_pois.calculate_dynamic_risk()

            # ğŸ•’ GÃ¼ncelleme zamanÄ±nÄ± kaydet
            with open(timestamp_file, "w") as f:
                f.write(datetime.today().strftime("%Y-%m-%d"))

            st.success("âœ… POI verisi baÅŸarÄ±yla gÃ¼ncellendi.")

            # ğŸ“„ SonuÃ§ dosyasÄ±nÄ± gÃ¶ster
            poi_path = "sf_pois_cleaned_with_geoid.csv"
            if os.path.exists(poi_path):
                df_poi = pd.read_csv(poi_path)
                st.write("ğŸ“Œ [sf_pois_cleaned_with_geoid.csv] sÃ¼tunlar:")
                st.write(df_poi.columns.tolist())
                st.write("ğŸ“‹ Ä°lk 3 satÄ±r:")
                st.dataframe(df_poi.head(3))
            else:
                st.warning("âš ï¸ POI dosyasÄ± bulunamadÄ± (sf_pois_cleaned_with_geoid.csv)")

        except Exception as e:
            st.error(f"âŒ POI gÃ¼ncelleme hatasÄ±: {e}")
    else:
        st.info("ğŸ“… POI verisi bu ay zaten gÃ¼ncellendi.")

def update_police_and_gov_buildings_if_needed():
    import requests
    import geopandas as gpd
    import pandas as pd
    import os
    from datetime import datetime
    from shapely.geometry import Point

    timestamp_file = "police_gov_last_update.txt"
    overpass_url = "http://overpass-api.de/api/interpreter"

    def is_month_passed(file):
        if os.path.exists(file):
            with open(file, "r") as f:
                last = f.read().strip()
            try:
                last_date = datetime.strptime(last, "%Y-%m-%d")
                return (datetime.today() - last_date).days >= 30
            except:
                return True
        return True

    if is_month_passed(timestamp_file):
        try:
            st.write("ğŸŒ Overpass API'den veri Ã§ekiliyor...")

            # === Overpass SorgularÄ± ===
            queries = {
                "police": """
                [out:json][timeout:60];
                (
                  node["amenity"="police"](37.70,-123.00,37.83,-122.35);
                  way["amenity"="police"](37.70,-123.00,37.83,-122.35);
                );
                out center;
                """,
                "government": """
                [out:json][timeout:60];
                (
                  node["amenity"="townhall"](37.70,-123.00,37.83,-122.35);
                  node["office"="government"](37.70,-123.00,37.83,-122.35);
                );
                out center;
                """
            }

            def fetch_pois(name, query):
                response = requests.post(overpass_url, data={"data": query})
                data = response.json()["elements"]
                rows = []
                for el in data:
                    lat = el.get("lat") or el.get("center", {}).get("lat")
                    lon = el.get("lon") or el.get("center", {}).get("lon")
                    if lat and lon:
                        tags = el.get("tags", {})
                        rows.append({
                            "id": el["id"],
                            "lat": lat,
                            "lon": lon,
                            "name": tags.get("name", ""),
                            "type": tags.get("amenity") or tags.get("office", ""),
                        })

                df = pd.DataFrame(rows)
                df["latitude"] = pd.to_numeric(df["lat"], errors="coerce")
                df["longitude"] = pd.to_numeric(df["lon"], errors="coerce")
                df = df.drop(columns=["lat", "lon"])
                gdf = gpd.GeoDataFrame(df.dropna(subset=["latitude", "longitude"]),
                                       geometry=gpd.points_from_xy(df["longitude"], df["latitude"]),
                                       crs="EPSG:4326")
                return gdf

            # ğŸ”¹ Polis istasyonlarÄ±nÄ± al
            gdf_police = fetch_pois("police", queries["police"])
            gdf_police.to_csv("sf_police_stations.csv", index=False)
            st.success("âœ… sf_police_stations.csv indirildi ve kaydedildi.")
            st.write("ğŸ“Œ Polis verisi sÃ¼tunlarÄ±:")
            st.write(gdf_police.columns.tolist())
            st.write("ğŸ“‹ Ä°lk 3 satÄ±r:")
            st.dataframe(gdf_police.head(3))

            # ğŸ”¹ Devlet binalarÄ±nÄ± al
            gdf_gov = fetch_pois("government", queries["government"])
            gdf_gov.to_csv("sf_government_buildings.csv", index=False)
            st.success("âœ… sf_government_buildings.csv indirildi ve kaydedildi.")
            st.write("ğŸ“Œ Devlet verisi sÃ¼tunlarÄ±:")
            st.write(gdf_gov.columns.tolist())
            st.write("ğŸ“‹ Ä°lk 3 satÄ±r:")
            st.dataframe(gdf_gov.head(3))

            # ğŸ”„ GÃ¼ncelleme zamanÄ±nÄ± yaz
            with open(timestamp_file, "w") as f:
                f.write(datetime.today().strftime("%Y-%m-%d"))

        except Exception as e:
            st.error(f"âŒ Polis/kamu binasÄ± gÃ¼ncelleme hatasÄ±: {e}")
    else:
        st.info("ğŸ“… Polis ve kamu binasÄ± verisi bu ay zaten gÃ¼ncellendi.")

def update_weather_data():
    import pandas as pd
    import streamlit as st
    import requests
    import os
    import io
    from datetime import datetime

    st.info("ğŸŒ¦ï¸ Hava durumu verisi kontrol ediliyor...")
    try:
        save_path = "sf_weather_5years.csv"
        station_id = "USW00023234"  # San Francisco Hava Ä°stasyonu
        end_date = datetime.today().date()
        start_date = end_date - pd.Timedelta(days=5 * 365)

        url = (
            "https://www.ncei.noaa.gov/access/services/data/v1"
            f"?dataset=daily-summaries"
            f"&stations={station_id}"
            f"&startDate={start_date}"
            f"&endDate={end_date}"
            f"&dataTypes=TMAX,TMIN,PRCP"
            f"&format=csv"
        )

        response = requests.get(url)
        if response.status_code == 200:
            df_new = pd.read_csv(io.StringIO(response.text))
            df_new["DATE"] = pd.to_datetime(df_new["DATE"])

            if os.path.exists(save_path):
                df_old = pd.read_csv(save_path)
                df_old["DATE"] = pd.to_datetime(df_old["DATE"])
                df_combined = pd.concat([df_old, df_new])
                df_combined = df_combined.drop_duplicates(subset=["DATE"])
            else:
                df_combined = df_new

            df_filtered = df_combined[df_combined["DATE"] >= pd.to_datetime(start_date)]
            df_filtered.to_csv(save_path, index=False)

            st.success(f"âœ… Hava durumu gÃ¼ncellendi: {start_date} â†’ {end_date}")

            # âœ… SonuÃ§ gÃ¶ster
            st.write("ğŸ“Œ [sf_weather_5years.csv] sÃ¼tunlar:")
            st.write(df_filtered.columns.tolist())
            st.write("ğŸ“‹ Ä°lk 3 satÄ±r:")
            st.dataframe(df_filtered.head(3))

        else:
            st.warning(f"âŒ NOAA'dan veri Ã§ekilemedi: {response.status_code}")
    except Exception as e:
        st.error(f"âŒ Hava durumu gÃ¼ncellenemedi: {e}")

def create_pdf_report(file_name, row_count_before, nan_cols, row_count_after, removed_rows):
    """Veri temizleme/iÅŸleme sonrasÄ± Ã¶zet PDF raporu oluÅŸturur."""
    now = datetime.now()
    timestamp = now.strftime("%d.%m.%Y %H:%M:%S")

    # NaN sÃ¼tunlarÄ±nÄ± metin olarak derle
    if not nan_cols.empty:
        nan_parts = [f"- {col}: {count}" for col, count in nan_cols.items()]
        nan_text = "\n".join(nan_parts)
    else:
        nan_text = "Yok"

    # Rapor metni
    summary = (
        f"ğŸ•’ Tarih/Saat: {timestamp}\n"
        f"ğŸ“„ Dosya: {file_name}\n"
        f"ğŸ“Š Toplam satÄ±r (Ã¶nce): {row_count_before:,}\n"
        f"ğŸ“‰ Toplam satÄ±r (sonra): {row_count_after:,}\n"
        f"ğŸ—‘ï¸ Silinen eski tarihli satÄ±r sayÄ±sÄ±: {removed_rows}\n"
        f"âš ï¸ NaN iÃ§eren sÃ¼tunlar:\n{nan_text}"
    )

    # PDF oluÅŸtur
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    pdf.multi_cell(0, 10, txt=summary.encode("latin1", "replace").decode("latin1"))

    # Dosya adÄ±nÄ± tarihli oluÅŸtur
    output_name = f"report_{now.strftime('%Y%m%d_%H%M%S')}.pdf"
    pdf.output(output_name)

    return output_name

if st.button("ğŸ“¥ sf_crime.csv indir, zenginleÅŸtir ve Ã¶zetle"):
    with st.spinner("â³ Ä°ÅŸlem devam ediyor..."):
        try:
            response = requests.get(DOWNLOAD_URL)
            if response.status_code == 200:
                with open("sf_crime.csv", "wb") as f:
                    f.write(response.content)
                st.success("âœ… sf_crime.csv baÅŸarÄ±yla indirildi.")
                
                # ğŸ” Dosya Ã¶nizlemesini gÃ¶ster
                try:
                    df_preview = pd.read_csv("sf_crime.csv")
                    st.write("ğŸ“Œ [sf_crime.csv] sÃ¼tunlar:")
                    st.write(df_preview.columns.tolist())
                    st.write("ğŸ“‹ Ä°lk 3 satÄ±r:")
                    st.dataframe(df_preview.head(3))
                except Exception as e:
                    st.warning(f"âš ï¸ sf_crime.csv Ã¶nizleme hatasÄ±: {e}")

                if os.path.exists("sf_pois_cleaned_with_geoid.csv"):
                    st.success("âœ… POI CSV dosyasÄ± mevcut.")
                    try:
                        df_poi_prev = pd.read_csv("sf_pois_cleaned_with_geoid.csv")
                        st.write("ğŸ“Œ [POI] SÃ¼tunlar:", df_poi_prev.columns.tolist())
                        st.dataframe(df_poi_prev.head(3))
                    except Exception as e:
                        st.warning(f"âš ï¸ POI dosyasÄ± okunamadÄ±: {e}")
                else:
                    st.error("âŒ POI CSV dosyasÄ± eksik!")

                if os.path.exists("risky_pois_dynamic.json"):
                    st.success("âœ… Risk skoru dosyasÄ± mevcut.")
                    try:
                        with open("risky_pois_dynamic.json") as f:
                            risk_data = json.load(f)
                        st.write("ğŸ“Œ [Risk Skoru JSON] Ä°lk 3 kayÄ±t:")
                        preview_risk = dict(list(risk_data.items())[:3])
                        st.json(preview_risk)
                    except Exception as e:
                        st.warning(f"âš ï¸ Risk skoru JSON okunamadÄ±: {e}")
                else:
                    st.error("âŒ Risk skoru JSON dosyasÄ± eksik!")

                try:
                    df_911 = None
                    response_911 = requests.get(DOWNLOAD_911_URL)
                    if response_911.status_code == 200:
                        with open("sf_911_last_5_year.csv", "wb") as f:
                            f.write(response_911.content)
                        st.success("âœ… 911 verisi indirildi.")
                        df_911 = pd.read_csv("sf_911_last_5_year.csv")

                        if "GEOID" in df_911.columns:
                            df_911["GEOID"] = df_911["GEOID"].astype(str).str.zfill(11)

                        if "event_hour" not in df_911.columns:
                            if "time" in df_911.columns:
                                df_911["event_hour"] = pd.to_datetime(df_911["time"], errors="coerce").dt.hour
                            elif "datetime" in df_911.columns:
                                df_911["event_hour"] = pd.to_datetime(df_911["datetime"], errors="coerce").dt.hour
                            else:
                                st.warning("âš ï¸ 'event_hour' Ã¼retilemedi.")

                        if "date" in df_911.columns:
                            df_911["date"] = pd.to_datetime(df_911["date"], errors="coerce").dt.date

                        st.dataframe(df_911.head())
                    else:
                        st.warning(f"âš ï¸ 911 verisi indirilemedi: {response_911.status_code}")
                except Exception as e:
                    st.error(f"âŒ 911 verisi iÅŸlenemedi: {e}")

                try:
                    df_311 = None
                    response_311 = requests.get(DOWNLOAD_311_URL)
                    if response_311.status_code == 200:
                        with open("sf_311_last_5_years.csv", "wb") as f:
                            f.write(response_311.content)
                        st.success("âœ… 311 verisi indirildi.")
                
                        # ğŸ“‹ Veriyi oku ve gÃ¶ster
                        try:
                            df_311 = pd.read_csv("sf_311_last_5_years.csv")
                            st.write("ğŸ“‹ [311] SÃ¼tunlar:", df_311.columns.tolist())
                            st.dataframe(df_311.head(3))
                        except Exception as e:
                            st.warning(f"âš ï¸ 311 verisi okunamadÄ±: {e}")
                    else:
                        st.warning(f"âš ï¸ 311 verisi indirilemedi: {response_311.status_code}")
                except Exception as e:
                    st.error(f"âŒ 311 verisi iÅŸlenemedi: {e}")

                df = pd.read_csv("sf_crime.csv", low_memory=False)
                original_row_count = len(df)
                
                try:
                    df_poi = pd.read_csv("sf_pois_cleaned_with_geoid.csv")
                    st.write("ğŸ“‹ [POI] SÃ¼tunlar:", df_poi.columns.tolist())
                    st.dataframe(df_poi.head(3))
                
                    with open("risky_pois_dynamic.json") as f:
                        risk_dict = json.load(f)
                
                    df_poi["risk_score"] = df_poi["poi_subcategory"].map(risk_dict).fillna(0)
                
                    # SuÃ§ geometrisi
                    gdf_crime = gpd.GeoDataFrame(
                        df,
                        geometry=gpd.points_from_xy(df["longitude"], df["latitude"]),
                        crs="EPSG:4326"
                    ).to_crs(3857)
                
                    # POI geometrisi
                    df_poi = df_poi.rename(columns={"lat": "poi_lat", "lon": "poi_lon"})
                    gdf_poi = gpd.GeoDataFrame(
                        df_poi,
                        geometry=gpd.points_from_xy(df_poi["poi_lon"], df_poi["poi_lat"]),
                        crs="EPSG:4326"
                    ).to_crs(3857)
                
                    # Mesafe hesapla
                    poi_coords = np.vstack([gdf_poi.geometry.x, gdf_poi.geometry.y]).T
                    crime_coords = np.vstack([gdf_crime.geometry.x, gdf_crime.geometry.y]).T
                    poi_tree = cKDTree(poi_coords)
                    df["distance_to_poi"], _ = poi_tree.query(crime_coords, k=1)
                
                    # Riskli POI mesafesi
                    risky_poi = gdf_poi[gdf_poi["risk_score"] > 0]
                    if not risky_poi.empty:
                        risky_coords = np.vstack([risky_poi.geometry.x, risky_poi.geometry.y]).T
                        risky_tree = cKDTree(risky_coords)
                        df["distance_to_high_risk_poi"], _ = risky_tree.query(crime_coords, k=1)
                    else:
                        df["distance_to_high_risk_poi"] = np.nan
                
                    # GEOID'e gÃ¶re risk yoÄŸunluÄŸu
                    risk_density = df_poi.groupby("GEOID")["risk_score"].mean().reset_index(name="poi_risk_density")
                    df = df.merge(risk_density, on="GEOID", how="left")
                
                    st.success("âœ… POI mesafe ve risk yoÄŸunluÄŸu eklendi.")
                    st.write("ğŸ“Œ Yeni SÃ¼tunlar:", ["distance_to_poi", "distance_to_high_risk_poi", "poi_risk_density"])
                    st.dataframe(df[["distance_to_poi", "distance_to_high_risk_poi", "poi_risk_density"]].head(3))
                
                except Exception as e:
                    st.error(f"âŒ POI mesafe/risk hesaplama hatasÄ±: {e}")

                if os.path.exists(POPULATION_PATH):
                    try:
                        df_pop = pd.read_csv(POPULATION_PATH)
                        st.write("ğŸ“‹ [NÃ¼fus] SÃ¼tunlar:", df_pop.columns.tolist())
                        st.dataframe(df_pop.head(3))
                
                        df["GEOID"] = df["GEOID"].astype(str).str.extract(r'(\d+)')[0].str.zfill(11)
                        df_pop["GEOID"] = df_pop["GEOID"].astype(str).str.zfill(11)
                
                        df = pd.merge(df, df_pop, on="GEOID", how="left")
                        df["population"] = df["population"].fillna(0).astype(int)
                
                        st.success("âœ… NÃ¼fus verisi eklendi.")
                        st.write("ğŸ‘¥ NÃ¼fus Ã¶rnek verisi (ilk 3 satÄ±r):")
                        st.dataframe(df[["GEOID", "population"]].drop_duplicates().head(3))
                    except Exception as e:
                        st.error(f"âŒ NÃ¼fus verisi iÅŸlenemedi: {e}")
                else:
                    st.warning("âš ï¸ NÃ¼fus verisi (sf_population.csv) bulunamadÄ±.")

                try:
                    # ğŸšŒ OtobÃ¼s verisi indir
                    response_bus = requests.get(DOWNLOAD_BUS_URL)
                    if response_bus.status_code == 200:
                        with open("sf_bus_stops.csv", "wb") as f:
                            f.write(response_bus.content)
                        st.success("âœ… sf_bus_stops.csv baÅŸarÄ±yla indirildi.")
                
                        try:
                            df_bus = pd.read_csv("sf_bus_stops.csv").dropna(subset=["stop_lat", "stop_lon"])
                            st.write("ğŸ“‹ [OtobÃ¼s] SÃ¼tunlar:", df_bus.columns.tolist())
                            st.write("ğŸšŒ OtobÃ¼s verisi (ilk 3 satÄ±r):")
                            st.dataframe(df_bus.head(3))
                        except Exception as e:
                            st.warning(f"âš ï¸ OtobÃ¼s CSV okunurken hata oluÅŸtu: {e}")
                    else:
                        st.warning(f"âš ï¸ OtobÃ¼s verisi indirilemedi: {response_bus.status_code}")
                except Exception as e:
                    st.error(f"âŒ OtobÃ¼s verisi indirilemedi: {e}")
                
                try:
                    # ğŸš† Tren verisi oku
                    if os.path.exists("sf_train_stops_with_geoid.csv"):
                        df_train = pd.read_csv("sf_train_stops_with_geoid.csv").dropna(subset=["stop_lat", "stop_lon"])
                        st.success("âœ… sf_train_stops_with_geoid.csv dosyasÄ± mevcut.")
                        st.write("ğŸ“‹ [Tren] SÃ¼tunlar:", df_train.columns.tolist())
                        st.write("ğŸš† Tren verisi (ilk 3 satÄ±r):")
                        st.dataframe(df_train.head(3))
                    else:
                        st.warning("âš ï¸ sf_train_stops_with_geoid.csv bulunamadÄ±.")
                except Exception as e:
                    st.error(f"âŒ Tren verisi okunamadÄ±: {e}")


                nan_summary = df.isna().sum()
                nan_cols = nan_summary[nan_summary > 0]
                removed_rows = 0
                removed_rows = original_row_count - len(df)
                report_path = create_pdf_report("sf_crime.csv", original_row_count, nan_cols, len(df), removed_rows)
                with open(report_path, "rb") as f:
                    st.download_button("ğŸ“„ PDF Raporu Ä°ndir", f, file_name=report_path, mime="application/pdf")

            else:
                st.error(f"âŒ sf_crime.csv indirilemedi, HTTP kodu: {response.status_code}")
                st.stop()

        except Exception as e:
            st.error(f"âŒ Genel hata oluÅŸtu: {e}")
            
# === Yardimci Fonksiyonlar ===
def check_and_fix_coordinates(df, context=""):
    """Koordinat sÃ¼tunlarÄ±nÄ± kontrol eder, dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve geÃ§ersiz deÄŸerleri temizler"""
    rename_map = {}
    if "latitude" not in df.columns:
        for alt in ["lat", "enlem"]:
            if alt in df.columns:
                rename_map[alt] = "latitude"
    if "longitude" not in df.columns:
        for alt in ["lon", "long", "lng", "boylam"]:
            if alt in df.columns:
                rename_map[alt] = "longitude"

    if rename_map:
        df.rename(columns=rename_map, inplace=True)
        st.warning(f"âš ï¸ {context}: {rename_map} olarak yeniden adlandÄ±rÄ±ldÄ±.")

    # Eksik sÃ¼tun varsa durdur
    if "latitude" not in df.columns or "longitude" not in df.columns:
        st.error(f"âŒ {context}: 'latitude' veya 'longitude' eksik.")
        return df.iloc[0:0]  # BoÅŸ DataFrame

    # SayÄ±sal dÃ¶nÃ¼ÅŸÃ¼m + filtre
    df["latitude"] = pd.to_numeric(df["latitude"], errors="coerce")
    df["longitude"] = pd.to_numeric(df["longitude"], errors="coerce")

    # GeÃ§ersiz koordinatlarÄ± at (Ã¶rneÄŸin: lat < 30, long > -100 gibi)
    df = df.dropna(subset=["latitude", "longitude"])
    df = df[
        (df["latitude"].between(37.5, 37.9)) & 
        (df["longitude"].between(-123, -122))
    ].copy()

    if df.empty:
        st.warning(f"âš ï¸ {context}: GeÃ§erli koordinat iÃ§eren satÄ±r yok.")
    return df
    
def enrich_with_911(df):
    try:
        df_911 = pd.read_csv("sf_911_last_5_year.csv")
        df_911["GEOID"] = df_911["GEOID"].astype(str).str.zfill(11)
        df["GEOID"] = df["GEOID"].astype(str).str.zfill(11)
        df_911["date"] = pd.to_datetime(df_911["date"], errors="coerce")
        df["date"] = pd.to_datetime(df["date"], errors="coerce")

        df = df.merge(
            df_911.rename(columns={
                "time": "call_time",
                "latitude": "call_lat",
                "longitude": "call_lon"
            }),
            on=["GEOID", "date", "event_hour"],
            suffixes=("", "_911")
        )
        return df
        
    except Exception as e:
        st.error(f"âŒ 911 verisi eklenemedi: {e}")
        return df

def enrich_with_311(df):
    try:
        df_311 = pd.read_csv("sf_311_last_5_years.csv")
        df_311["datetime"] = pd.to_datetime(df_311["date"] + " " + df_311["time"], errors="coerce")
        df_311["event_hour"] = df_311["datetime"].dt.hour
        df_311["date"] = pd.to_datetime(df_311["date"]).dt.date
        df["date"] = pd.to_datetime(df["date"]).dt.date

        df_311["GEOID"] = df_311["GEOID"].astype(str).str.zfill(11)
        df["GEOID"] = df["GEOID"].astype(str).str.zfill(11)

        df = df.merge(
            df_311.rename(columns={
                "time": "request_time",
                "category": "service_category"
            }),
            on=["GEOID", "date", "event_hour"],
            suffixes=("", "_311")
        )
        return df

    except Exception as e:
        st.error(f"âŒ 311 verisi eklenemedi: {e}")
        return df

def enrich_with_weather(df):
    try:
        if not os.path.exists("sf_weather_5years.csv"):
            st.warning("âš ï¸ Hava durumu verisi bulunamadÄ±")
            return df

        weather = pd.read_csv("sf_weather_5years.csv")
        weather.columns = weather.columns.str.lower()
        date_col = next((col for col in weather.columns if 'date' in col), None)
        if not date_col:
            st.error("âŒ Hava durumu verisinde tarih sÃ¼tunu bulunamadÄ±")
            return df

        weather['date'] = pd.to_datetime(weather[date_col]).dt.date
        df['date'] = pd.to_datetime(df['date']).dt.date

        df = df.merge(
            weather.rename(columns={"date": "weather_date"}),
            left_on="date",
            right_on="weather_date",
            suffixes=("", "_weather")
        ).drop(columns=["weather_date"])
        st.success("âœ… Hava durumu verisi baÅŸarÄ±yla eklendi")
        return df

    except Exception as e:
        st.error(f"âŒ Hava durumu zenginleÅŸtirme hatasÄ±: {str(e)}")
        return df

def enrich_with_police(df):
    try:
        # 1. SuÃ§ verisinde koordinatlarÄ± kontrol et
        df_checked = check_and_fix_coordinates(df.copy(), "Polis istasyonu entegrasyonu")
        if df_checked.empty:
            st.warning("âš ï¸ Polis: GeÃ§erli suÃ§ koordinatÄ± bulunamadÄ±.")
            return df

        df_valid = df_checked.dropna(subset=["longitude", "latitude"]).copy()

        # 2. Polis verisi dosyasÄ±nÄ± kontrol et
        if not os.path.exists("sf_police_stations.csv"):
            st.error("âŒ Polis istasyonu verisi bulunamadÄ± (sf_police_stations.csv)")
            return df

        df_police = pd.read_csv("sf_police_stations.csv")

        # 3. Polis verisinde koordinatlarÄ± kontrol et
        df_police_checked = check_and_fix_coordinates(df_police.copy(), "Polis istasyonu verisi")
        if df_police_checked.empty:
            st.warning("âš ï¸ Polis: GeÃ§erli istasyon koordinatÄ± yok.")
            return df

        # 4. GeoDataFrame oluÅŸtur
        gdf_crime = gpd.GeoDataFrame(
            df_valid,
            geometry=gpd.points_from_xy(df_valid["longitude"], df_valid["latitude"]),
            crs="EPSG:4326"
        ).to_crs(epsg=3857)

        gdf_police = gpd.GeoDataFrame(
            df_police_checked,
            geometry=gpd.points_from_xy(df_police_checked["longitude"], df_police_checked["latitude"]),
            crs="EPSG:4326"
        ).to_crs(epsg=3857)

        # 5. Mesafe hesapla
        crime_coords = np.vstack([gdf_crime.geometry.x, gdf_crime.geometry.y]).T
        police_coords = np.vstack([gdf_police.geometry.x, gdf_police.geometry.y]).T
        police_tree = cKDTree(police_coords)

        df_valid["distance_to_police"], _ = police_tree.query(crime_coords, k=1)
        df_valid["is_near_police"] = (df_valid["distance_to_police"] < 200).astype(int)
        df_valid["distance_to_police_range"] = pd.cut(
            df_valid["distance_to_police"],
            bins=[0, 100, 200, 500, 1000, np.inf],
            labels=["0-100", "100-200", "200-500", "500-1000", ">1000"]
        )

        # 6. Ana df ile gÃ¼ncelle
        df.update(df_valid)
        st.success("âœ… Polis istasyonu bilgileri baÅŸarÄ±yla eklendi")
        return df

    except Exception as e:
        st.error(f"âŒ Polis istasyonu zenginleÅŸtirme hatasÄ±: {str(e)}")
        return df

def enrich_with_government(df):
    try:
        # 1. SuÃ§ verisi koordinatlarÄ±nÄ± kontrol et
        df_checked = check_and_fix_coordinates(df, "Devlet binalarÄ± entegrasyonu")
        if df_checked.empty:
            st.warning("âš ï¸ Devlet binalarÄ±: GeÃ§erli suÃ§ koordinatÄ± bulunamadÄ±.")
            return df

        df_valid = df_checked.dropna(subset=["longitude", "latitude"]).copy()

        # 2. Devlet binasÄ± dosyasÄ±nÄ± kontrol et
        if not os.path.exists("sf_government_buildings.csv"):
            st.error("âŒ Devlet binalarÄ± verisi bulunamadÄ±")
            return df

        df_gov = pd.read_csv("sf_government_buildings.csv")

        # 3. Devlet binasÄ± koordinatlarÄ±nÄ± kontrol et
        df_gov_checked = check_and_fix_coordinates(df_gov, "Devlet binalarÄ± verisi")
        if df_gov_checked.empty:
            st.warning("âš ï¸ Devlet binalarÄ±: GeÃ§erli istasyon koordinatÄ± yok.")
            return df

        # 4. GeoDataFrame dÃ¶nÃ¼ÅŸÃ¼mleri
        gdf_crime = gpd.GeoDataFrame(
            df_valid,
            geometry=gpd.points_from_xy(df_valid["longitude"], df_valid["latitude"]),
            crs="EPSG:4326"
        ).to_crs(epsg=3857)

        gdf_gov = gpd.GeoDataFrame(
            df_gov_checked,
            geometry=gpd.points_from_xy(df_gov_checked["longitude"], df_gov_checked["latitude"]),
            crs="EPSG:4326"
        ).to_crs(epsg=3857)

        # 5. Mesafe hesapla
        crime_coords = np.vstack([gdf_crime.geometry.x, gdf_crime.geometry.y]).T
        gov_coords = np.vstack([gdf_gov.geometry.x, gdf_gov.geometry.y]).T
        gov_tree = cKDTree(gov_coords)

        df_valid["distance_to_government"], _ = gov_tree.query(crime_coords, k=1)
        df_valid["is_near_government"] = (df_valid["distance_to_government"] < 200).astype(int)
        df_valid["distance_to_government_range"] = pd.cut(
            df_valid["distance_to_government"],
            bins=[0, 100, 200, 500, 1000, np.inf],
            labels=["0-100m", "100-200m", "200-500m", "500-1000m", ">1000m"]
        )

        # 6. Ana df'e geri yaz
        df.update(df_valid)
        st.success("âœ… Devlet binasÄ± bilgileri baÅŸarÄ±yla eklendi")
        return df

    except Exception as e:
        st.error(f"âŒ Devlet binasÄ± zenginleÅŸtirme hatasÄ±: {str(e)}")
        return df


# Veri zenginleÅŸtirme 

def check_and_fix_coordinates(df, context=""):
    rename_map = {}
    if "latitude" not in df.columns:
        for alt in ["lat", "enlem"]:
            if alt in df.columns:
                rename_map[alt] = "latitude"
    if "longitude" not in df.columns:
        for alt in ["lon", "long", "lng", "boylam"]:
            if alt in df.columns:
                rename_map[alt] = "longitude"

    if rename_map:
        df.rename(columns=rename_map, inplace=True)
        st.warning(f"âš ï¸ {context}: {rename_map} olarak yeniden adlandÄ±rÄ±ldÄ±.")

    if "latitude" not in df.columns or "longitude" not in df.columns:
        st.error(f"âŒ {context}: 'latitude' veya 'longitude' eksik.")
        return df.iloc[0:0]

    df["latitude"] = pd.to_numeric(df["latitude"], errors="coerce")
    df["longitude"] = pd.to_numeric(df["longitude"], errors="coerce")
    df = df.dropna(subset=["latitude", "longitude"])

    # Daha geniÅŸ aralÄ±k
    df = df[
        (df["latitude"].between(37.7, 37.84)) & 
        (df["longitude"].between(-123.2, -122.3))
    ].copy()

    if df.empty:
        st.warning(f"âš ï¸ {context}: GeÃ§erli koordinat iÃ§eren satÄ±r yok.")
    return df


def enrich_with_poi(df):
    """
    SuÃ§ verisini POI (Point of Interest) verileriyle zenginleÅŸtirir.
    - En yakÄ±n POI'ya ve en yakÄ±n riskli POI'ya olan mesafeleri hesaplar.
    - Her coÄŸrafi bÃ¶lge (GEOID) iÃ§in POI risk yoÄŸunluÄŸunu hesaplar.
    """
    try:
        # Gerekli dosyalarÄ± yÃ¼kle
        df_poi = pd.read_csv("sf_pois_cleaned_with_geoid.csv")
        with open("risky_pois_dynamic.json") as f:
            risk_dict = json.load(f)
        
        # Risk skorunu ata
        df_poi["risk_score"] = df_poi["poi_subcategory"].map(risk_dict).fillna(0)

        # GeoDataFrame'leri oluÅŸtur ve projeksiyonu ayarla (hesaplama iÃ§in)
        gdf_crime = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df["longitude"], df["latitude"]), crs="EPSG:4326").to_crs(3857)
        gdf_poi = gpd.GeoDataFrame(df_poi, geometry=gpd.points_from_xy(df_poi["lon"], df_poi["lat"]), crs="EPSG:4326").to_crs(3857)

        # KDTree ile en yakÄ±n POI mesafesini hesapla
        poi_coords = np.vstack([gdf_poi.geometry.x, gdf_poi.geometry.y]).T
        crime_coords = np.vstack([gdf_crime.geometry.x, gdf_crime.geometry.y]).T
        poi_tree = cKDTree(poi_coords)
        df["distance_to_poi"], _ = poi_tree.query(crime_coords, k=1)

        # YÃ¼ksek riskli POI'lar iÃ§in mesafeyi hesapla
        risky_poi = gdf_poi[gdf_poi["risk_score"] > 0]
        if not risky_poi.empty:
            risky_coords = np.vstack([risky_poi.geometry.x, risky_poi.geometry.y]).T
            risky_tree = cKDTree(risky_coords)
            df["distance_to_high_risk_poi"], _ = risky_tree.query(crime_coords, k=1)
        else:
            df["distance_to_high_risk_poi"] = np.nan
        
        # GEOID bazÄ±nda risk yoÄŸunluÄŸunu hesapla ve ana dataframe'e ekle
        risk_density = df_poi.groupby("GEOID")["risk_score"].mean().reset_index(name="poi_risk_density")
        df = df.merge(risk_density, on="GEOID", how="left")
        
        st.success("âœ… POI mesafesi ve risk yoÄŸunluÄŸu baÅŸarÄ±yla eklendi.")
        return df

    except Exception as e:
        st.error(f"âŒ POI zenginleÅŸtirme sÄ±rasÄ±nda hata oluÅŸtu: {e}")
        return df # Hata durumunda bile orijinal df'i geri dÃ¶ndÃ¼r

def enrich_with_police(df):
    st.write("ğŸ“Œ SÃ¼tunlar:", df.columns.tolist())
    st.write("ğŸ“‹ Ä°lk 5 satÄ±r (koordinatlar):")
    st.write(df[["latitude", "longitude"]].head())
    st.write("â— Eksik latitude sayÄ±sÄ±:", df["latitude"].isna().sum())
    st.write("â— Eksik longitude sayÄ±sÄ±:", df["longitude"].isna().sum())
    try:
        # 1. SuÃ§ verisinde koordinatlarÄ± kontrol et
        df_checked = check_and_fix_coordinates(df.copy(), "Polis istasyonu entegrasyonu")
        if df_checked.empty:
            st.warning("âš ï¸ Polis: GeÃ§erli suÃ§ koordinatÄ± bulunamadÄ±.")
            return df

        df_valid = df_checked.dropna(subset=["longitude", "latitude"]).copy()

        # 2. Polis verisi dosyasÄ±nÄ± kontrol et
        if not os.path.exists("sf_police_stations.csv"):
            st.error("âŒ Polis istasyonu verisi bulunamadÄ± (sf_police_stations.csv)")
            return df

        df_police = pd.read_csv("sf_police_stations.csv")

        # 3. Polis verisinde koordinatlarÄ± kontrol et
        df_police_checked = check_and_fix_coordinates(df_police.copy(), "Polis istasyonu verisi")
        if df_police_checked.empty:
            st.warning("âš ï¸ Polis: GeÃ§erli istasyon koordinatÄ± yok.")
            return df

        # 4. GeoDataFrame oluÅŸtur
        gdf_crime = gpd.GeoDataFrame(
            df_valid,
            geometry=gpd.points_from_xy(df_valid["longitude"], df_valid["latitude"]),
            crs="EPSG:4326"
        ).to_crs(epsg=3857)

        gdf_police = gpd.GeoDataFrame(
            df_police_checked,
            geometry=gpd.points_from_xy(df_police_checked["longitude"], df_police_checked["latitude"]),
            crs="EPSG:4326"
        ).to_crs(epsg=3857)

        # 5. Mesafe hesapla
        crime_coords = np.vstack([gdf_crime.geometry.x, gdf_crime.geometry.y]).T
        police_coords = np.vstack([gdf_police.geometry.x, gdf_police.geometry.y]).T
        police_tree = cKDTree(police_coords)

        df_valid["distance_to_police"], _ = police_tree.query(crime_coords, k=1)
        df_valid["is_near_police"] = (df_valid["distance_to_police"] < 200).astype(int)
        df_valid["distance_to_police_range"] = pd.cut(
            df_valid["distance_to_police"],
            bins=[0, 100, 200, 500, 1000, np.inf],
            labels=["0-100", "100-200", "200-500", "500-1000", ">1000"]
        )

        # 6. Orijinal df ile gÃ¼ncelle
        df.update(df_valid)
        st.success("âœ… Polis istasyonu bilgileri baÅŸarÄ±yla eklendi")
        return df

    except Exception as e:
        st.error(f"âŒ Polis istasyonu zenginleÅŸtirme hatasÄ±: {str(e)}")
        return df
        
def enrich_with_government(df):
    """SuÃ§ verisini devlet binalarÄ± verileriyle zenginleÅŸtirir"""
    try:
        # 1. SuÃ§ verisi koordinatlarÄ±nÄ± kontrol et
        df_checked = check_and_fix_coordinates(df.copy(), "Devlet binalarÄ± entegrasyonu")
        if df_checked.empty:
            st.warning("âš ï¸ Devlet binalarÄ±: GeÃ§erli suÃ§ koordinatÄ± bulunamadÄ±.")
            return df

        df_valid = df_checked.dropna(subset=["longitude", "latitude"]).copy()

        # 2. Devlet binasÄ± dosyasÄ±nÄ± kontrol et
        if not os.path.exists("sf_government_buildings.csv"):
            st.error("âŒ Devlet binalarÄ± verisi bulunamadÄ±")
            return df

        df_gov = pd.read_csv("sf_government_buildings.csv")

        # 3. Devlet binasÄ± koordinatlarÄ±nÄ± kontrol et
        df_gov_checked = check_and_fix_coordinates(df_gov.copy(), "Devlet binalarÄ± verisi")
        if df_gov_checked.empty:
            st.warning("âš ï¸ Devlet binalarÄ±: GeÃ§erli istasyon koordinatÄ± yok.")
            return df

        # 4. GeoDataFrame dÃ¶nÃ¼ÅŸÃ¼mleri
        gdf_crime = gpd.GeoDataFrame(
            df_valid,
            geometry=gpd.points_from_xy(df_valid["longitude"], df_valid["latitude"]),
            crs="EPSG:4326"
        ).to_crs(epsg=3857)

        gdf_gov = gpd.GeoDataFrame(
            df_gov_checked,
            geometry=gpd.points_from_xy(df_gov_checked["longitude"], df_gov_checked["latitude"]),
            crs="EPSG:4326"
        ).to_crs(epsg=3857)

        # 5. Mesafe hesapla
        crime_coords = np.vstack([gdf_crime.geometry.x, gdf_crime.geometry.y]).T
        gov_coords = np.vstack([gdf_gov.geometry.x, gdf_gov.geometry.y]).T
        gov_tree = cKDTree(gov_coords)

        df_valid["distance_to_government"], _ = gov_tree.query(crime_coords, k=1)
        df_valid["is_near_government"] = (df_valid["distance_to_government"] < 200).astype(int)
        df_valid["distance_to_government_range"] = pd.cut(
            df_valid["distance_to_government"],
            bins=[0, 100, 200, 500, 1000, np.inf],
            labels=["0-100m", "100-200m", "200-500m", "500-1000m", ">1000m"]
        )

        # 6. Ana df'e geri yaz
        df.update(df_valid)
        st.success("âœ… Devlet binasÄ± bilgileri baÅŸarÄ±yla eklendi")
        return df

    except Exception as e:
        st.error(f"âŒ Devlet binasÄ± zenginleÅŸtirme hatasÄ±: {str(e)}")
        return df

def enrich_with_911(df):
    try:
        df_911 = pd.read_csv("sf_911_last_5_year.csv")

        # GEOID'leri string ve 11 haneli olarak ayarla
        df_911["GEOID"] = df_911["GEOID"].astype(str).str.zfill(11)
        df["GEOID"] = df["GEOID"].astype(str).str.zfill(11)

        # Tarih formatÄ± dÃ¼zelt
        df_911["date"] = pd.to_datetime(df_911["date"], errors="coerce")
        df["date"] = pd.to_datetime(df["date"], errors="coerce")

        # Merge iÅŸlemi
        df = df.merge(
            df_911.rename(columns={
                "time": "call_time",
                "latitude": "call_lat",
                "longitude": "call_lon"
            }),
            on=["GEOID", "date", "event_hour"],
            suffixes=("", "_911")
        )
        return df

    except Exception as e:
        st.error(f"âŒ 911 verisi eklenemedi: {e}")
        return df

def enrich_with_311(df):
    try:
        df_311 = pd.read_csv("sf_311_last_5_years.csv")

        # datetime birleÅŸtirme ve saat Ã§Ä±karÄ±mÄ±
        df_311["datetime"] = pd.to_datetime(df_311["date"] + " " + df_311["time"], errors="coerce")
        df_311["event_hour"] = df_311["datetime"].dt.hour
        df_311["hour_range"] = (df_311["event_hour"] // 3) * 3
        df_311["hour_range"] = df_311["hour_range"].astype(str) + "-" + (df_311["hour_range"] + 3).astype(str)

        # tarih formatÄ± dÃ¼zelt
        df_311["date"] = pd.to_datetime(df_311["date"]).dt.date
        df["date"] = pd.to_datetime(df["date"]).dt.date

        # GEOID tipleri uyuÅŸmalÄ±
        df_311["GEOID"] = df_311["GEOID"].astype(str).str.zfill(11)
        df["GEOID"] = df["GEOID"].astype(str).str.zfill(11)

        # saat eÅŸleÅŸmesiyle birleÅŸtir
        df = df.merge(
            df_311.rename(columns={
                "time": "request_time",
                "category": "service_category"
            }),
            on=["GEOID", "date", "event_hour"],
            suffixes=("", "_311")
        )
        return df

    except Exception as e:
        st.error(f"âŒ 311 verisi eklenemedi: {e}")
        return df

def enrich_with_weather(df):
    try:
        if not os.path.exists("sf_weather_5years.csv"):
            st.warning("âš ï¸ Hava durumu verisi bulunamadÄ±")
            return df

        weather = pd.read_csv("sf_weather_5years.csv")
        weather.columns = weather.columns.str.lower()
        
        # Tarih sÃ¼tununu bulmak iÃ§in esnek yaklaÅŸÄ±m
        date_col = next((col for col in weather.columns if 'date' in col), None)
        if not date_col:
            st.error("âŒ Hava durumu verisinde tarih sÃ¼tunu bulunamadÄ±")
            return df
            
        weather['date'] = pd.to_datetime(weather[date_col]).dt.date
        
        # Ana veride tarih sÃ¼tununu bul
        main_date_col = 'date' if 'date' in df.columns else \
                       next((col for col in df.columns if 'date' in col), None)
        
        if not main_date_col:
            st.error("âŒ Ana veride tarih sÃ¼tunu bulunamadÄ±")
            return df
            
        # datetime sÃ¼tunu yoksa oluÅŸtur
        if 'datetime' not in df.columns and 'date' in df.columns and 'time' in df.columns:
            try:
                df['datetime'] = pd.to_datetime(df['date'].astype(str) + ' ' + df['time'].astype(str))
            except:
                df['datetime'] = pd.to_datetime(df['date'].astype(str))
        
        df['date'] = pd.to_datetime(df[main_date_col]).dt.date
        
        # BirleÅŸtirme
        df = df.merge(
            weather.rename(columns={"date": "weather_date"}),
            left_on="date",
            right_on="weather_date",
            suffixes=("", "_weather")
        ).drop(columns=["weather_date"])
        st.success("âœ… Hava durumu verisi baÅŸarÄ±yla eklendi")
        return df

    except Exception as e:
        st.error(f"âŒ Hava durumu zenginleÅŸtirme hatasÄ±: {str(e)}")
        return df
        
if st.button("ğŸ§ª Veriyi GÃ¶ster (Test)"):
    try:
        # Veri yÃ¼kleme
        if not os.path.exists("sf_crime.csv"):
            st.error("âŒ sf_crime.csv bulunamadÄ±!")
            st.stop()
            
        df = pd.read_csv("sf_crime.csv", low_memory=False)
        
        # Koordinat kontrolÃ¼
        df = check_and_fix_coordinates(df, "Ana veri")
        if df.empty:
            st.warning("âš ï¸ Ana veri: GeÃ§erli koordinat iÃ§eren satÄ±r yok.")
            st.stop()

        # Tarih/saat iÅŸlemleri
        if 'date' in df.columns and 'time' in df.columns:
            try:
                df['datetime'] = pd.to_datetime(df['date'].astype(str) + ' ' + df['time'].astype(str))
                df['date'] = df['datetime'].dt.date
                df['event_hour'] = df['datetime'].dt.hour
            except Exception as e:
                st.error(f"âŒ Tarih dÃ¶nÃ¼ÅŸÃ¼m hatasÄ±: {str(e)}")
        
        # ZenginleÅŸtirme adÄ±mlarÄ±
        enrichment_functions = [
            ("POI", enrich_with_poi),
            ("911", enrich_with_911),
            ("311", enrich_with_311),
            ("Hava Durumu", enrich_with_weather),
            ("Polis Ä°stasyonlarÄ±", enrich_with_police),
            ("Devlet BinalarÄ±", enrich_with_government)
        ]
        
        for name, func in enrichment_functions:
            try:
                df = func(df)
            except Exception as e:
                st.error(f"âŒ {name} zenginleÅŸtirme hatasÄ±: {str(e)}")
        
        # SonuÃ§larÄ± gÃ¶ster
        st.write("### SonuÃ§lar")
        st.dataframe(df.head(3))
        st.write("SÃ¼tunlar:", df.columns.tolist())
        
    except Exception as e:
        st.error(f"âŒ Genel hata: {str(e)}")
